{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "284e73d5",
   "metadata": {
    "id": "284e73d5"
   },
   "source": [
    "**RNN**\n",
    "In this code, we first set the parameters such as the maximum number of words to consider as features (max_features), the maximum sequence length (max_length), batch size, and the number of epochs for training.\n",
    "\n",
    "We then load the IMDb dataset using imdb.load_data(). The dataset is automatically split into training and testing sets. We apply padding to the sequences using sequence.pad_sequences() to ensure all input sequences have the same length (It pads the vectors with zeros in order to match the length).\n",
    "\n",
    "The RNN model is built using tf.keras.Sequential with an embedding layer, a simple RNN layer, and a dense layer with sigmoid activation for binary classification. The Embedding layer is a text-embedding layer which groups similar meaning words together in the vector space (which is kept as 32 Dimentional). While training, we also train the embedding so that our model learns the correct embeddings on our own.\n",
    "\n",
    "The model is compiled with the RMSprop optimizer, binary cross-entropy loss, and accuracy as the evaluation metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc9680a2",
   "metadata": {
    "id": "fc9680a2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f444678",
   "metadata": {
    "id": "3f444678"
   },
   "outputs": [],
   "source": [
    "max_features = 5000  # Number of words to consider as features\n",
    "max_length = 250  # Maximum sequence length (words)\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "# Load the IMDb dataset\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "L0ejVroBEHpP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L0ejVroBEHpP",
    "outputId": "094c299d-9ff1-4557-8036-a1d3936dcc98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4iCdrUIcENLL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4iCdrUIcENLL",
    "outputId": "4a32160e-797f-46b6-a178-05b5cad08897"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 2,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 2,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 2,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 2,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 2,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0] #ouputs some numbers which are some kind of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aYWMFWF3EZ-j",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aYWMFWF3EZ-j",
    "outputId": "e66189f8-7fa5-475d-ba48-cdc10681dc2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0] #positive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "NvtGsutIEd5N",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NvtGsutIEd5N",
    "outputId": "4572aff9-b46b-4dfe-8dbe-e74bee5a7c1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "word_index['bad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "zWZ3QMXsEuyN",
   "metadata": {
    "id": "zWZ3QMXsEuyN"
   },
   "outputs": [],
   "source": [
    "get_word = dict((value,key) for key,value in word_index.items())\n",
    "def decode(review):\n",
    "  txt = ''\n",
    "  for r in review:\n",
    "    txt += get_word[r]\n",
    "    txt += \" \"\n",
    "\n",
    "  return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "KG7JMdAzFezA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "KG7JMdAzFezA",
    "outputId": "c92ea967-be0c-4ff2-cf95-49a3e431f357"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"the exercise he it is tony falls ask has is found and and david order besides and it age cole watch extraordinary would it racist bad them can of order this community dancer of introduced for at does for all with released movies sometimes to for be war rock made all it coming all well fighting in cheap not his movie high and and actors know bad can and chance 6 and and and in and or weren't to and is got say room and legend like that hand some it of and br about help of you it is over are of straight able of their book an of details have stuff that in not that it her and anyone who so and down course and to and for have big 3 not also global she this of played and there theatre will life are goes in still lion to would to and he and who is success save br being before this television god is nobody to tony ask for into and to and have \""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(x_train[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23OVW24xGYhI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23OVW24xGYhI",
    "outputId": "3382e007-8606-4c81-87b6-7983fbb98ee8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "n5jvwFLtF2n3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n5jvwFLtF2n3",
    "outputId": "5de167c9-78fa-4d93-928a-46c626f8c56f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[19] #seems like a positive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9eb70d1e",
   "metadata": {
    "id": "9eb70d1e"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Pad sequences to a fixed length because each size is differnt\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_length)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53e0f59",
   "metadata": {
    "id": "a53e0f59",
    "outputId": "87beb125-9512-4cd5-8de8-3ea8ee54e93f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 61s 77ms/step - loss: 0.5793 - accuracy: 0.6682 - val_loss: 0.4069 - val_accuracy: 0.8248\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 63s 81ms/step - loss: 0.3682 - accuracy: 0.8416 - val_loss: 0.4093 - val_accuracy: 0.8101\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 70s 89ms/step - loss: 0.2991 - accuracy: 0.8767 - val_loss: 0.4193 - val_accuracy: 0.8175\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 72s 92ms/step - loss: 0.2807 - accuracy: 0.8900 - val_loss: 0.3600 - val_accuracy: 0.8634\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 83s 106ms/step - loss: 0.2279 - accuracy: 0.9100 - val_loss: 0.4651 - val_accuracy: 0.7915\n",
      "782/782 [==============================] - 14s 17ms/step - loss: 0.4651 - accuracy: 0.7915\n",
      "Test loss: 0.4651\n",
      "Test accuracy: 0.7915\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build the RNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(max_features, 32),\n",
    "    tf.keras.layers.SimpleRNN(32),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print(f'Test loss: {loss:.4f}')\n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb667a9",
   "metadata": {},
   "source": [
    "##### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc80dda8",
   "metadata": {
    "id": "cc80dda8"
   },
   "source": [
    "In this code, we use an LSTM layer instead of a RNN layer since RNNs are expected to suffer from vanishing gradients.\n",
    "\n",
    "The number of layers, features, padding, epochs, optimisers are set the same as earlier to make the comparison as fair as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2bc2b0",
   "metadata": {
    "id": "bb2bc2b0",
    "outputId": "33698287-beb2-4e7c-a40a-5a85beda51ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 144s 179ms/step - loss: 0.4444 - accuracy: 0.7870 - val_loss: 0.3533 - val_accuracy: 0.8447\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 145s 185ms/step - loss: 0.2932 - accuracy: 0.8821 - val_loss: 0.3037 - val_accuracy: 0.8714\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 149s 190ms/step - loss: 0.2602 - accuracy: 0.8981 - val_loss: 0.3270 - val_accuracy: 0.8725\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 140s 179ms/step - loss: 0.2378 - accuracy: 0.9075 - val_loss: 0.3222 - val_accuracy: 0.8708\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 145s 185ms/step - loss: 0.2206 - accuracy: 0.9151 - val_loss: 0.4134 - val_accuracy: 0.8660\n",
      "782/782 [==============================] - 33s 43ms/step - loss: 0.4134 - accuracy: 0.8660\n",
      "Test loss: 0.4134\n",
      "Test accuracy: 0.8660\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "# Set the parameters\n",
    "max_features = 5000  # Number of words to consider as features\n",
    "max_length = 250  # Maximum sequence length (words)\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "# Load the IMDb dataset\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# Pad sequences to a fixed length\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_length)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_length)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(max_features, 32),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print(f'Test loss: {loss:.4f}')\n",
    "print(f'Test accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60e00d5",
   "metadata": {
    "id": "7460218c"
   },
   "source": [
    "As expected, we get a better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4220cfdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
